{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"LangGraph Quickstart\"\n",
    "author: \"Kedar Dabhadkar\"\n",
    "date: 2026-01-08\n",
    "description: \"Setting up a LangGraph graph, invoking it, and streaming responses\"\n",
    "type: technical_note\n",
    "categories: [\"Python\", \"LLM\", \"LangGraph\"]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install langgraph langchain-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Define State and Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define state schema\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Define node function\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Build and Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Invoke the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic invocation - returns final state\n",
    "result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]})\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Streaming Methods\n",
    "\n",
    "LangGraph offers three streaming approaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### 1. Stream State Updates (`stream`)\n",
    "\n",
    "Yields state after each node completes. Good for tracking graph progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"Hi\"}]}):\n",
    "    print(state)  # {'chatbot': {'messages': [AIMessage(...)]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### 2. Stream LLM Tokens (`astream_events`)\n",
    "\n",
    "Streams individual tokens from LLM calls. Best for real-time chat UIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in graph.astream_events(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi\"}]},\n",
    "    version=\"v2\"\n",
    "):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\":\n",
    "        print(event[\"data\"][\"chunk\"].content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### 3. Stream with Mode Selection\n",
    "\n",
    "Use `stream_mode` parameter for different output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"values\" - full state at each step\n",
    "for state in graph.stream(input, stream_mode=\"values\"):\n",
    "    print(state[\"messages\"][-1])\n",
    "\n",
    "# \"updates\" - only changes from each node (default)\n",
    "for update in graph.stream(input, stream_mode=\"updates\"):\n",
    "    print(update)\n",
    "\n",
    "# \"messages\" - stream message chunks directly\n",
    "for msg, metadata in graph.stream(input, stream_mode=\"messages\"):\n",
    "    print(msg.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9n7oadhmnfj",
   "source": "### 4. Custom Streaming Mode\n\nDefine your own streaming format using `stream_mode=\"custom\"` with a `StreamWriter`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8z12dw91gyb",
   "source": "from langgraph.config import get_stream_writer\n\ndef my_node(state: State):\n    writer = get_stream_writer()\n    \n    # Stream custom data during node execution\n    writer({\"status\": \"processing\", \"step\": 1})\n    result = llm.invoke(state[\"messages\"])\n    writer({\"status\": \"complete\", \"step\": 2})\n    \n    return {\"messages\": [result]}\n\n# Consume custom stream\nfor chunk in graph.stream(input, stream_mode=\"custom\"):\n    print(chunk)  # {\"status\": \"processing\", \"step\": 1}, etc.",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": "## Quick Reference\n\n| Method | Use Case | Output |\n|--------|----------|--------|\n| `invoke()` | Simple calls | Final state |\n| `stream()` | Node-by-node progress | State updates |\n| `stream(stream_mode=\"messages\")` | Chat UI streaming | Message chunks |\n| `stream(stream_mode=\"custom\")` | Custom progress/status | User-defined data |\n| `astream_events()` | Fine-grained token streaming | All LLM events |"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}