{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Using Python Requests with Server-Sent Events (SSE)\"\n",
        "author: \"Kedar Dabhadkar\"\n",
        "date: 2026-01-03\n",
        "description: \"A quick tutorial on consuming SSE streams with the requests library\"\n",
        "type: technical_note\n",
        "categories: [\"Python\", \"LLM\"]\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Server-Sent Events (SSE) is a standard for pushing real-time updates from a server to a client over HTTP. It's commonly used by LLM APIs (like OpenAI, Anthropic, etc.) to stream responses token-by-token.\n",
        "\n",
        "This tutorial shows how to consume SSE streams using Python's `requests` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is SSE?\n",
        "\n",
        "SSE is a one-way communication channel where the server sends events to the client. Each event follows this format:\n",
        "\n",
        "```\n",
        "event: message\n",
        "data: {\"key\": \"value\"}\n",
        "\n",
        "event: message  \n",
        "data: {\"key\": \"another_value\"}\n",
        "```\n",
        "\n",
        "Events are separated by double newlines (`\\n\\n`), and each line is prefixed with a field name like `data:`, `event:`, `id:`, or `retry:`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic SSE Consumption with Requests\n",
        "\n",
        "The key is to use `stream=True` and iterate over the response line by line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def consume_sse(url, headers=None, payload=None):\n",
        "    \"\"\"Basic SSE consumer using requests.\"\"\"\n",
        "    \n",
        "    response = requests.post(\n",
        "        url,\n",
        "        headers=headers,\n",
        "        json=payload,\n",
        "        stream=True  # This is crucial for SSE\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    # Iterate over the response line by line\n",
        "    for line in response.iter_lines():\n",
        "        if line:\n",
        "            decoded_line = line.decode('utf-8')\n",
        "            \n",
        "            # SSE data lines start with 'data: '\n",
        "            if decoded_line.startswith('data: '):\n",
        "                data = decoded_line[6:]  # Remove 'data: ' prefix\n",
        "                \n",
        "                # Many APIs use '[DONE]' to signal end of stream\n",
        "                if data == '[DONE]':\n",
        "                    break\n",
        "                    \n",
        "                yield data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parsing JSON from SSE Events\n",
        "\n",
        "Most APIs send JSON data in their SSE events. Here's how to parse it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "def consume_sse_json(url, headers=None, payload=None):\n",
        "    \"\"\"SSE consumer that parses JSON data.\"\"\"\n",
        "    \n",
        "    response = requests.post(\n",
        "        url,\n",
        "        headers=headers,\n",
        "        json=payload,\n",
        "        stream=True\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    for line in response.iter_lines():\n",
        "        if line:\n",
        "            decoded_line = line.decode('utf-8')\n",
        "            \n",
        "            if decoded_line.startswith('data: '):\n",
        "                data = decoded_line[6:]\n",
        "                \n",
        "                if data == '[DONE]':\n",
        "                    break\n",
        "                \n",
        "                try:\n",
        "                    yield json.loads(data)\n",
        "                except json.JSONDecodeError:\n",
        "                    # Handle non-JSON data if needed\n",
        "                    yield data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real-World Example: OpenAI-Compatible API\n",
        "\n",
        "Here's a practical example for streaming from an OpenAI-compatible API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "def stream_chat_completion(api_url, api_key, messages, model=\"gpt-4\"):\n",
        "    \"\"\"Stream chat completions from an OpenAI-compatible API.\"\"\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Accept\": \"text/event-stream\",  # Explicitly request SSE\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": messages,\n",
        "        \"stream\": True,  # Enable streaming\n",
        "    }\n",
        "    \n",
        "    response = requests.post(\n",
        "        api_url,\n",
        "        headers=headers,\n",
        "        json=payload,\n",
        "        stream=True\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    full_response = \"\"\n",
        "    \n",
        "    for line in response.iter_lines():\n",
        "        if line:\n",
        "            decoded_line = line.decode('utf-8')\n",
        "            \n",
        "            if decoded_line.startswith('data: '):\n",
        "                data = decoded_line[6:]\n",
        "                \n",
        "                if data == '[DONE]':\n",
        "                    break\n",
        "                \n",
        "                try:\n",
        "                    chunk = json.loads(data)\n",
        "                    # Extract the content delta\n",
        "                    delta = chunk.get('choices', [{}])[0].get('delta', {})\n",
        "                    content = delta.get('content', '')\n",
        "                    \n",
        "                    if content:\n",
        "                        full_response += content\n",
        "                        print(content, end='', flush=True)  # Print as we receive\n",
        "                        \n",
        "                except json.JSONDecodeError:\n",
        "                    pass\n",
        "    \n",
        "    print()  # New line at the end\n",
        "    return full_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage (replace with your actual API details)\n",
        "# response = stream_chat_completion(\n",
        "#     api_url=\"https://api.openai.com/v1/chat/completions\",\n",
        "#     api_key=\"your-api-key\",\n",
        "#     messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handling Timeouts and Errors\n",
        "\n",
        "SSE streams can be long-running. Here's how to handle timeouts gracefully:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "from requests.exceptions import ChunkedEncodingError, ConnectionError, Timeout\n",
        "\n",
        "def robust_sse_consumer(url, headers=None, payload=None, timeout=60):\n",
        "    \"\"\"SSE consumer with error handling.\"\"\"\n",
        "    \n",
        "    try:\n",
        "        response = requests.post(\n",
        "            url,\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            stream=True,\n",
        "            timeout=(5, timeout)  # (connect timeout, read timeout)\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        for line in response.iter_lines():\n",
        "            if line:\n",
        "                decoded_line = line.decode('utf-8')\n",
        "                \n",
        "                if decoded_line.startswith('data: '):\n",
        "                    data = decoded_line[6:]\n",
        "                    \n",
        "                    if data == '[DONE]':\n",
        "                        break\n",
        "                    \n",
        "                    try:\n",
        "                        yield json.loads(data)\n",
        "                    except json.JSONDecodeError:\n",
        "                        yield {\"raw\": data}\n",
        "                        \n",
        "    except Timeout:\n",
        "        yield {\"error\": \"Request timed out\"}\n",
        "    except ConnectionError:\n",
        "        yield {\"error\": \"Connection failed\"}\n",
        "    except ChunkedEncodingError:\n",
        "        yield {\"error\": \"Stream interrupted\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Using sseclient-py\n",
        "\n",
        "For more complex SSE handling, consider using the `sseclient-py` library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install sseclient-py\n",
        "\n",
        "import requests\n",
        "import sseclient\n",
        "\n",
        "def consume_sse_with_library(url, headers=None, payload=None):\n",
        "    \"\"\"Using sseclient-py for cleaner SSE handling.\"\"\"\n",
        "    \n",
        "    response = requests.post(\n",
        "        url,\n",
        "        headers=headers,\n",
        "        json=payload,\n",
        "        stream=True\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    client = sseclient.SSEClient(response)\n",
        "    \n",
        "    for event in client.events():\n",
        "        if event.data == '[DONE]':\n",
        "            break\n",
        "        yield event.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Always use `stream=True`** - This prevents requests from buffering the entire response\n",
        "2. **Use `iter_lines()`** - This gives you the response line by line as it arrives\n",
        "3. **Parse the `data:` prefix** - SSE events have this prefix before the actual data\n",
        "4. **Handle `[DONE]`** - Many APIs use this to signal the end of the stream\n",
        "5. **Set appropriate timeouts** - SSE streams can be long-running, so plan accordingly\n",
        "6. **Consider using `sseclient-py`** - For complex SSE handling with proper event parsing"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
